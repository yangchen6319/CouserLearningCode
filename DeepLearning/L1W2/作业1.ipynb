{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1使用numpy构建基本函数\n",
    "### 1.1 sigmoid函数和np.exp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2.71828183  7.3890561  20.08553692]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "x = np.array([1,2,3])\n",
    "print(np.exp(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.73105858 0.88079708 0.95257413]\n"
     ]
    }
   ],
   "source": [
    "# 使用np.exp构建sigmoid函数\n",
    "def sigmoid(x):\n",
    "    s = 1/(1+np.exp(-x))\n",
    "    return s\n",
    "\n",
    "print(sigmoid(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Sigmoid gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_gradient(x):\n",
    "    s = 1/(1+np.exp(-x))\n",
    "    ds = s * (1-s)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.19661193 0.10499359 0.04517666]\n"
     ]
    }
   ],
   "source": [
    "print(sigmoid_gradient(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 重塑数组"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape(array):\n",
    "    v = array.reshape(array.shape[0]*array.shape[1]*array.shape[2],1)\n",
    "    return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0. 0.]\n",
      "  [0. 0.]\n",
      "  [0. 0.]\n",
      "  [0. 0.]]\n",
      "\n",
      " [[0. 0.]\n",
      "  [0. 0.]\n",
      "  [0. 0.]\n",
      "  [0. 0.]]\n",
      "\n",
      " [[0. 0.]\n",
      "  [0. 0.]\n",
      "  [0. 0.]\n",
      "  [0. 0.]]]\n"
     ]
    }
   ],
   "source": [
    "array_1 = np.zeros((3,4,2))\n",
    "print(array_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n"
     ]
    }
   ],
   "source": [
    "print(reshape(array_1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 行标准化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizeRows(x):\n",
    "    # 按照行求范数\n",
    "    x_norm = np.linalg.norm(x,axis=1,keepdims=True)\n",
    "    # 标准化\n",
    "    x = x/x_norm\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.26726124 0.53452248 0.80178373]\n",
      " [0.45584231 0.56980288 0.68376346]]\n"
     ]
    }
   ],
   "source": [
    " x = np.array([[1,2,3],[4,5,6]])\n",
    " print(normalizeRows(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 广播和softmax函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    x_exp = np.exp(x)\n",
    "    x_sum = np.sum(x_exp,axis=1, keepdims=True)\n",
    "    x = x_exp / x_sum\n",
    "    return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7.20860803e-01 6.57339966e-04 1.32030262e-02 8.89612905e-05\n",
      "  2.65189869e-01]\n",
      " [8.78679856e-01 1.18916387e-01 8.01252314e-04 8.01252314e-04\n",
      "  8.01252314e-04]]\n"
     ]
    }
   ],
   "source": [
    "x = np.array([[9, 2, 5, 0, 8],[7, 5, 0, 0, 0]])\n",
    "print(softmax(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 向量化\n",
    "### 2.1 实现L1和L2损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def L1(y_hat, y):\n",
    "    loss = np.sum(np.abs(y - y_hat))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def L2(y_hat, y):\n",
    "    loss = np.sum((y-y_hat)**2)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L1 = 1.1\n",
      "L2 = 0.43\n"
     ]
    }
   ],
   "source": [
    "# 测试上述两个损失函数\n",
    "y_hat = np.array([0.9, 0.2, 0.1, 0.4, 0.9])\n",
    "y = np.array([1, 0, 0, 1, 1])\n",
    "print(\"L1 = \"+str(L1(y_hat, y)))\n",
    "print(\"L2 = \"+str(L2(y_hat, y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
